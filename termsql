#!/bin/python
#
#The MIT License (MIT)
#
#Copyright (c) 2014 Tobias Glaesser
#
#Permission is hereby granted, free of charge, to any person obtaining a copy
#of this software and associated documentation files (the "Software"), to deal
#in the Software without restriction, including without limitation the rights
#to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#copies of the Software, and to permit persons to whom the Software is
#furnished to do so, subject to the following conditions:
#
#The above copyright notice and this permission notice shall be included in all
#copies or substantial portions of the Software.
#
#THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
#SOFTWARE.

#NOTICE: please contribute improvements back to the project, it's very much appreciated

#TODO:
#-escape strings before for insertion into database
#-fix --head feature
#-

import fileinput
import subprocess
import sys
import argparse
import tempfile
import os
import sqlite3
import locale

locale.setlocale(locale.LC_ALL, '')

VERSION = "0.3alpha"
#configureable default values
sqlite_cmd = 'sqlite3'
table_name = 'tbl'
sql_db_file = ''
delimiter = ' '
separator = '' #default to whatever sqlite defaults to
mode = 'list'
columns = ''
offset_head = 0
max_rows = 0
queryfile_data = ''
query_off = False
merge = None

epilog_expanded = False
if os.environ.get('MORE_HELP') == 'True':
    epilog_expanded = True

epilog_more =  '''  termsql -i MyCSVFile.CSV -t fancytable -d ',' -1 -o mysqlite.db
    (creates a new sqlite database from a CSV file. -d ',' tells termsql to use commata as delimiter. -1 tells termsql that the first line of the CSV file is not data and instead the column names and termsql creates database columns with those names accordingly. -t fancytable sets the tablename to fancytable)
  sensors | termsql "select COL2 from tbl where COL0='Core'"
    (extract the temperature from all your CPU cores)
  export LC_ALL=en_US; 
  top -b | head | termsql -1 -H 6 "select [PID],[USER],[COMMAND],[%CPU] from tbl where [%CPU]>=25"
    (termsql doesn't recognize numbers like "25,3" as numbers, but as strings. export LC_ALL=en_US ensures that top outputs numbers that are easy for termsql/sqlite to digest (ie. "25.3"). -H 6 makes termsql disregard the first 6 lines. We select only the processes with more than 25% cpu usage and output their PID,USER,COMMAND and %CPU.)
  export DISPLAY=$(ps aux | termsql "select COL11 from tbl where COL10 like '%Xorg.bin%' limit 1")
    (set DISPLAY environment variable to what display X is running on right now, assuming that the X binary is called "Xorg.bin")
'''
if not epilog_expanded:
    epilog_more = '''
To get more examples type `man termsql` or set `MORE_HELP=True` and run `termsql -h` again. Thanks for using termsql.'''

#setup command line parser
parser = argparse.ArgumentParser(description='Convert text into SQL table and query it', formatter_class=argparse.RawDescriptionHelpFormatter, epilog='''examples:
  ps aux | termsql "select * from tbl where COL0='root' limit 5"
    (outputs 5 processes that are running as root)
  df | termsql -1 'select Filesystem from tbl order by [1K-blocks] desc limit 1'
    (return the largest device)
  cat /proc/cpuinfo | termsql "select COL2 from tbl where COL0='bogomips'"
    (how many bogomips does your system have?)
  termsql --infile /etc/group -d ':' "select COL0 from tbl"
    (read from file, use : as delimiter, shows all groups in /etc/group)
'''+epilog_more
)
parser.add_argument("query", nargs='?', default='', help="SQL Query string")
parser.add_argument("-1", "--head", help="use first line/head(er) for column names", action="store_true")
parser.add_argument("-d", "--delimiter",  nargs='?', help="custom delimiter (default is whitespace)") 
parser.add_argument("-p","--separator", nargs='?', help="set sqlite output field separator (default depends on output mode. ie. for list '|' is the default and for csv ',' is the default) ")
parser.add_argument("-l","--line-as-column", nargs='?', help="each line of input is a whole column, next row begins after n lines")
parser.add_argument("-k","--key-columns", nargs='?', help="one or more columns can make up the primary key (i.e -k COL0 or -c name,nick -k nick)")
parser.add_argument("-c","--columns", nargs='?', help="set custom column names (ie. -c 'name,street,age')")
parser.add_argument("-w","--whitespace", help="use whitespace as field separator (default is |). equal to mode column",action="store_true")
parser.add_argument("-H","--offset-head", nargs='?', help="ignore first n lines of input",type=int)
parser.add_argument("-T","--offset-tail", nargs='?', help="ignore last n lines of input")
parser.add_argument("-M","--max-rows", nargs='?', help="don't insert more than n rows into database")
parser.add_argument("-C","--dump-create-table", help="dump create table SQL",action="store_true")
parser.add_argument("-D","--dump", help="dump complete SQL to create table and content",action="store_true")
parser.add_argument("-m","--mode", nargs='?', help="set sqlite output mode i.e.: csv, column, html, insert, line, list, tabs, tcl (default is list)")
parser.add_argument("-r","--merge", nargs='?', help="merges all columns from column n to the last one into one. This is useful when you have data like filenames with whitespaces in it, to prevent it from getting split by the delimiter. Note that counting starts from 0, therefore n=0 is the first column ...")
parser.add_argument("-x","--select-all", help="add final SELECT * FROM to user defined query",action="store_true")
parser.add_argument("-a","--append", help="don't DROP TABLE instead just append data to existing table. If the existing table doesn't have enough columns it will be ALTERed accordingly, if possible",action="store_true")
parser.add_argument("-i","--infile",  nargs='?', help="use file as input instead of stdin")
parser.add_argument("-o","--outfile", nargs='?', help="location/filename to use for sql database (by default a tempfile is used)")
parser.add_argument("-q","--queryfile", nargs='?', help="load complex query from file, queries on the commandline get executed last")
parser.add_argument("-t","--table", nargs='?', help="tablename (must be a valid sqlite tablename)")
parser.add_argument("-s","--sqlite", nargs='?', help="path to sqlite executable")
parser.add_argument("-v","--version", help="display version information", action="store_true")
args = parser.parse_args()


#process command line input
if args.mode:
    mode = args.mode.lower()
if args.delimiter:
    delimiter = args.delimiter
if args.separator:
    separator = args.separator
if args.whitespace:
    mode = 'column'
if args.merge:
    merge = int(args.merge)
if args.outfile:
    sql_db_file = args.outfile
if args.table:
    table_name = args.table
if args.infile:
    infile = open(args.infile)
else:
    infile = sys.stdin
if args.sqlite:
    sqlite_cmd = args.sqlite
if args.columns:
    columns = [x.strip() for x in args.columns.split(',')]
if args.offset_head:
    offset_head = args.offset_head
if args.queryfile:
    queryfile_data = open(args.queryfile).read()
if args.version:
    print VERSION
    exit(0)   

#simplify subprocess.call
def shell(str):
    subprocess.call(str, shell=True)

colnames = [] #only needed when using --head optional arg

#get name of column x
def get_col_name(i):
    if args.columns and len(columns) > i:
        return columns[i]
    elif args.head and len(colnames) > i:
        return colnames[i]
    else:
        return "COL"+str(i)

inserts = []

def isfloat(value):
  try:
    locale.atof(value)
    return True
  except ValueError:
    return False

colprobs = {}
def update_colprobs(col,data):
    if not col in colprobs:
        colprobs[col] = {}
        colprobs[col]["INTEGER"] = True
        colprobs[col]["REAL"] = True
        colprobs[col]["TEXT"] = True
    if not data.isdigit():
        colprobs[col]["INTEGER"] = False        
    if not isfloat(data):
        colprobs[col]["REAL"] = False
    if "MAXLEN" not in colprobs[col] or len(data) > colprobs[col]["MAXLEN"]:
        colprobs[col]["MAXLEN"] = len(data)

def get_col_type(col):
    if not col in colprobs:
        return "TEXT"
    elif colprobs[col]["INTEGER"]:
        return "INTEGER"
    elif colprobs[col]["REAL"]:
        return "REAL"
    return "TEXT"

insert_count = 0
#build sql string to insert row
def build_insert(row):
    insert = []
    c = 0
    for col in row:
        if merge != None and c > merge:
            insert[-1] = str(insert[-1]) + delimiter + str(col)
            update_colprobs(merge,insert[-1])
        else:
            insert.append(col)
            update_colprobs(c,col)
        c += 1
    inserts.append(insert)

#get column names using row
def get_col_names(row):
    count = 0
    for col in row:
        colnames.append(col)
        count += 1

#traverse input
max_count = 0    
lines = infile.readlines()
if offset_head > 0:
    del lines[:int(args.offset_head)]

if not args.line_as_column:
    first_line = True
    for line in lines:
        if args.max_rows and insert_count >= int(args.max_rows):
            break
        if delimiter != ' ':
            row = line.rstrip('\r\n').split(delimiter)
        else:
            row = line.split()        
        if len(row) > max_count:
            max_count = len(row)
        if first_line and args.head:
            get_col_names(row)
        else:
            build_insert(row)
            insert_count += 1
        first_line = False
else:
    max_count = int(args.line_as_column)
    col_count = 0 
    while len(lines) > 0:
        row = []
        while True:
            row.append(lines.pop(0).strip())
            col_count += 1
            if not int(args.line_as_column) > col_count:
                col_count = 0
                break
        if args.max_rows and insert_count >= int(args.max_rows):
            break
        build_insert(row)
        insert_count += 1

if len(colprobs) < max_count:
    max_count = len(colprobs)

temp = []
for ins in inserts:
    ins.extend([None] * (max_count - len(ins)))
    temp.append(ins)
inserts = temp

#create create database string
if max_count > 0:
    create_table_string =  "create table \""+table_name+"\"("
    for x in range(0,max_count):
        if x > 0:
            create_table_string += ", "
        create_table_string += '"'+ get_col_name(x) + '"' + " " + get_col_type(x)
    create_table_string += ");"
else:
    exit(0)

if sql_db_file == '':
    f = tempfile.NamedTemporaryFile()
    sql_db_file = f.name

conn = sqlite3.connect(sql_db_file)
conn.text_factory = str
c = conn.cursor()

c.execute("drop table if exists \""+table_name+"\";")
#create database and databasefile
c.execute(create_table_string)
if args.dump_create_table:
    print create_table_string
    query_off = True

temp = []
temp.extend('?' * (max_count))
placeholder_str = ",".join(temp)

if args.offset_tail and int(args.offset_tail) > 0:
    del inserts[-int(args.offset_tail):]

#execute inserts, fill table with row data
c.executemany('insert into tbl values ('+placeholder_str+')', inserts)
conn.commit()
                     
actual_query = args.query
if actual_query == "" and queryfile_data == '':
   actual_query = "select * from \""+table_name+"\""
elif args.select_all:
   actual_query = actual_query +  ";select * from \""+table_name+"\""

if queryfile_data != '':
   actual_query = queryfile_data + ';' + actual_query

temp_query_file = tempfile.NamedTemporaryFile(delete=False)
temp_query_file.write(actual_query + ";")
temp_query_file.close()

init_file = tempfile.NamedTemporaryFile(delete=False) #temporary file that we give sqlite for initializing settings such as mode

column_width_string = ''
for col in colprobs:
    column_width_string = column_width_string + ' ' + str(colprobs[col]["MAXLEN"])

if mode == 'insert':
    init_file.write("\n.mode \"" + mode + "\" "+table_name+"\n")
else:
    init_file.write("\n.mode \"" + mode + "\"\n")
if mode == 'column':
    #init_file.write("\n.header yes\n")
    init_file.write("\n.width "+column_width_string+"\n")
if separator != '':
    init_file.write(".separator \"" + separator + "\"\n")
if args.dump:
    init_file.write(".dump\n")
    query_off = True
if not query_off:
    init_file.write(".read \"" + temp_query_file.name + "\"\n")

init_file.close()

command_string = sqlite_cmd + ' -init ' + init_file.name + ' '  + sql_db_file

#for row in c.execute(args.query):
#    print '|'.join((item or '') for item in row )

# echo " " | is a hack to prevent sqlite from getting into interactive model, maybe there is a more pythonic method
shell('echo " " | ' + command_string)

os.unlink(init_file.name)
os.unlink(temp_query_file.name)

#print colprobs
